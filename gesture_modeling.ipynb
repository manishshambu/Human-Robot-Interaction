{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio  # for reading in video files\n",
    "\n",
    "# Imports the Google Cloud client library\n",
    "from google.cloud import speech\n",
    "from google.cloud.speech import enums\n",
    "from google.cloud.speech import types\n",
    "\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from __future__ import print_function, division, unicode_literals\n",
    "import json\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "sys.path.insert(0, \"/Users/anuj/coursework_cuboulder/spring_2018/algo_hri/torchMoji-master\")\n",
    "\n",
    "from torchmoji.sentence_tokenizer import SentenceTokenizer\n",
    "from torchmoji.model_def import torchmoji_emojis\n",
    "from torchmoji.global_variables import PRETRAINED_PATH, VOCAB_PATH\n",
    "\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_video_file(filename):\n",
    "    vid = imageio.get_reader(filename, 'ffmpeg')\n",
    "    return vid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio_from_video(video_filename):\n",
    "    video_filename = video_filename.split(' ')\n",
    "    video_filename = '\\ '.join(video_filename)\n",
    "    \n",
    "    rmp = video_filename.split('.mp4')\n",
    "    rmp.append('.wav')\n",
    "    output_audio_filename = ''.join(rmp)\n",
    "        \n",
    "    command = \"ffmpeg -i \"+video_filename+\" -ab 160k -ac 2 -ar 44100 -vn \"+output_audio_filename\n",
    "    subprocess.call(command, shell=True)\n",
    "    \n",
    "    print('audio saved to', output_audio_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def get_skeleton_frames_consolidated_dict(directory):\n",
    "    # key = frame index\n",
    "    # value = parts position dictionary (part number: [x,y,z,c] -- pixel coordinates)\n",
    "    skeleton_frames_dict = {}\n",
    "\n",
    "    # TODO: why are some part positions empty?\n",
    "    # TODO: get 3D coordinates intead of 2D\n",
    "    for idx, skeleton_frame_filename in enumerate(sorted(os.listdir(directory))):\n",
    "        json_contents = json.load(open(directory + skeleton_frame_filename))\n",
    "        part_pos_dict = json_contents['part_candidates'][0]\n",
    "        if idx not in skeleton_frames_dict.keys():\n",
    "            skeleton_frames_dict[idx] = {}\n",
    "        skeleton_frames_dict[idx] = part_pos_dict\n",
    "        \n",
    "    return skeleton_frames_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Warning: the frame size for reading (480, 848) is different from the source frame size (848, 480).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1146, 90)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Check if number of frames extracted from original video == number of frames from OpenPose\n",
    "\"\"\"\n",
    "\n",
    "video_filename = 'WhatsApp Video 2018-04-12 at 10.16.35 PM.mp4'\n",
    "skeleton_json_folder = 'json/'\n",
    "\n",
    "vid = read_video_file(video_filename)\n",
    "\n",
    "skeleton_frames_dict = get_skeleton_frames_consolidated_dict(skeleton_json_folder)\n",
    "\n",
    "vid.get_meta_data()['nframes'], len(skeleton_frames_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_audio_to_mono(audio_filename):\n",
    "    output_filename = 'mono_'+audio_filename\n",
    "    command = ['sox', audio_filename, '-c', '1', output_filename] \n",
    "    subprocess.Popen(command)\n",
    "    \n",
    "    print('mono audio saved to', output_filename)\n",
    "    return output_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_speech(audio_filename):\n",
    "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"google_creds.json\"\n",
    "\n",
    "    audio_filename = convert_audio_to_mono(audio_filename)\n",
    "\n",
    "    # Instantiates a client\n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "    # Loads the audio into memory\n",
    "    with io.open(audio_filename, 'rb') as audio_file:\n",
    "        content = audio_file.read()\n",
    "        audio = types.RecognitionAudio(content=content)\n",
    "\n",
    "    config = types.RecognitionConfig(language_code='en-US')\n",
    "\n",
    "    # Detects speech in the audio file\n",
    "    response = client.recognize(config, audio)\n",
    "    \n",
    "    return response.results[0].alternatives[0].transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emotion_features_from_text(text):\n",
    "    text = [text]\n",
    "    def top_elements(array, k):\n",
    "        ind = np.argpartition(array, -k)[-k:]\n",
    "        return ind[np.argsort(array[ind])][::-1]\n",
    "\n",
    "    maxlen = 30\n",
    "\n",
    "    print('Tokenizing using dictionary from {}'.format(VOCAB_PATH))\n",
    "    with open(VOCAB_PATH, 'r') as f:\n",
    "        vocabulary = json.load(f)\n",
    "\n",
    "    st = SentenceTokenizer(vocabulary, maxlen)\n",
    "\n",
    "    print('Loading model from {}.'.format(PRETRAINED_PATH))\n",
    "    model = torchmoji_emojis(PRETRAINED_PATH)\n",
    "    print(model)\n",
    "    print('Running predictions.')\n",
    "    tokenized, _, _ = st.tokenize_sentences(text)\n",
    "    prob = model(tokenized)\n",
    "\n",
    "    for prob in [prob]:\n",
    "        # Find top emojis for each sentence. Emoji ids (0-63)\n",
    "        # correspond to the mapping in emoji_overview.png\n",
    "        # at the root of the torchMoji repo.\n",
    "        #print('Writing results to {}'.format(OUTPUT_PATH))\n",
    "        scores = []\n",
    "        for i, t in enumerate(text):\n",
    "            t_tokens = tokenized[i]\n",
    "            t_score = [t]\n",
    "            t_prob = prob[i]\n",
    "            ind_top = top_elements(t_prob, 5)\n",
    "            t_score.append(sum(t_prob[ind_top]))\n",
    "            t_score.extend(ind_top)\n",
    "            t_score.extend([t_prob[ind] for ind in ind_top])\n",
    "            scores.append(t_score)\n",
    "    \n",
    "    emoji_ids = scores[0][2:2+5]\n",
    "    one_hot_encodings = []\n",
    "    for emoji_idx in emoji_ids:\n",
    "        one_hot_encodings.append([0 if i!=emoji_idx else 1 for i in range(64)])\n",
    "    return emoji_ids, one_hot_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prosody_features_from_audio(audio_filename):\n",
    "    audio_filename = convert_audio_to_mono(audio_filename)\n",
    "    command = 'python /Users/anuj/coursework_cuboulder/spring_2018/algo_hri/DisVoice-master/prosody/prosody.py \\\"'+audio_filename+'\\\" \\\"prosody_'+ audio_filename+'.txt\\\" \"static\" \"false\"'\n",
    "    subprocess.call(command, shell=True)\n",
    "    \n",
    "    print('prosody features saved to prosody_' + audio_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame by frame speech to text convert..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
